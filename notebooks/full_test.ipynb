{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from looti import cosmo_emulator as cem\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load trained emulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Looti = cem.CosmoEmulator(external_info={'config_yaml': '../readfile_configs/read_input4cast.yaml'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['folders_path', 'params_file', 'reference_folder', 'save_path', 'save_name', 'z_file_name', 'k_file_name', 'ells_file_name', 'data_file_names', 'data_types', 'training_redshifts', 'n_samples', 'n_training_samples', 'n_test_samples', 'csv_zip', 'fileformat', 'n_folders', 'folders'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Looti.FileReader.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data frame for :  Plin\n",
      " Reference k-dataframe created \n",
      "Looping over 600 folders\n",
      "Maximum number of n_samples reached\n",
      "Time needed for Dataframe creation 48.8731\n",
      "Number of parameters varying: 8\n",
      "Parameters: ['w0_fld', 'wa_fld', 'Omega_m', 'Omega_b', 'h', 'n_s', 'A_s', 'sigma8']\n",
      "Number of samples in dataset: 600\n",
      "Dataframe saved to: ../training_data/class_Asw0wa_DP_cmb_2K_Plin.csv.zip\n",
      "Reference dataframe saved to: ../training_data/class_Asw0wa_DP_cmb_2K_Plin_ref.csv.zip\n",
      "------------------------------------------\n",
      "Creating data frame for :  Pnonlin\n",
      " Reference k-dataframe created \n",
      "Looping over 600 folders\n",
      "Maximum number of n_samples reached\n",
      "Time needed for Dataframe creation 52.5827\n",
      "Number of parameters varying: 8\n",
      "Parameters: ['w0_fld', 'wa_fld', 'Omega_m', 'Omega_b', 'h', 'n_s', 'A_s', 'sigma8']\n",
      "Number of samples in dataset: 600\n",
      "Dataframe saved to: ../training_data/class_Asw0wa_DP_cmb_2K_Pnonlin.csv.zip\n",
      "Reference dataframe saved to: ../training_data/class_Asw0wa_DP_cmb_2K_Pnonlin_ref.csv.zip\n",
      "------------------------------------------\n",
      "Creating data frame for :  f_GrowthRate\n",
      " Reference k-dataframe created \n",
      "Looping over 600 folders\n",
      "Maximum number of n_samples reached\n",
      "Time needed for Dataframe creation 52.3037\n",
      "Number of parameters varying: 8\n",
      "Parameters: ['w0_fld', 'wa_fld', 'Omega_m', 'Omega_b', 'h', 'n_s', 'A_s', 'sigma8']\n",
      "Number of samples in dataset: 600\n",
      "Dataframe saved to: ../training_data/class_Asw0wa_DP_cmb_2K_f_GrowthRate.csv.zip\n",
      "Reference dataframe saved to: ../training_data/class_Asw0wa_DP_cmb_2K_f_GrowthRate_ref.csv.zip\n",
      "------------------------------------------\n",
      "Creating data frame for :  sigma8\n",
      " Reference z-dataframe created \n",
      "Looping over 600 folders\n",
      "Number of parameters varying: 8\n",
      "Parameters: ['w0_fld', 'wa_fld', 'Omega_m', 'Omega_b', 'h', 'n_s', 'A_s', 'sigma8']\n",
      "Number of samples in dataset: 600\n",
      "Dataframe saved to: ../training_data/class_Asw0wa_DP_cmb_2K_sigma8.csv.zip\n",
      "Reference dataframe saved to: ../training_data/class_Asw0wa_DP_cmb_2K_sigma8_ref.csv.zip\n",
      "------------------------------------------\n",
      "Creating data frame for :  background_H\n",
      " Reference z-dataframe created \n",
      "Looping over 600 folders\n",
      "Number of parameters varying: 8\n",
      "Parameters: ['w0_fld', 'wa_fld', 'Omega_m', 'Omega_b', 'h', 'n_s', 'A_s', 'sigma8']\n",
      "Number of samples in dataset: 600\n",
      "Dataframe saved to: ../training_data/class_Asw0wa_DP_cmb_2K_background_H.csv.zip\n",
      "Reference dataframe saved to: ../training_data/class_Asw0wa_DP_cmb_2K_background_H_ref.csv.zip\n",
      "------------------------------------------\n",
      "Creating data frame for :  TT\n",
      " Reference z-dataframe created \n",
      "Looping over 600 folders\n",
      "Number of parameters varying: 8\n",
      "Parameters: ['w0_fld', 'wa_fld', 'Omega_m', 'Omega_b', 'h', 'n_s', 'A_s', 'sigma8']\n",
      "Number of samples in dataset: 600\n",
      "Dataframe saved to: ../training_data/class_Asw0wa_DP_cmb_2K_TT.csv.zip\n",
      "Reference dataframe saved to: ../training_data/class_Asw0wa_DP_cmb_2K_TT_ref.csv.zip\n",
      "------------------------------------------\n",
      "Creating data frame for :  TE\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "../../raw_data/class_Asw0wa_DP_cmb_2K/0000/TE_cls.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/santiago/CosmoProjects/Looti_container/looti/notebooks/full_test.ipynb Cell 5\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/santiago/CosmoProjects/Looti_container/looti/notebooks/full_test.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Looti\u001b[39m.\u001b[39;49mcreate_dataframes()\n",
      "File \u001b[0;32m~/CosmoProjects/Looti_container/looti/looti/cosmo_emulator.py:19\u001b[0m, in \u001b[0;36mcreate_dataframes\u001b[0;34m(self)\u001b[0m\n",
      "File \u001b[0;32m~/CosmoProjects/Looti_container/looti/looti/read_files.py:71\u001b[0m, in \u001b[0;36mFileReader.create_dataframes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m     df_ext\u001b[39m.\u001b[39mto_csv(save_data_string)\n\u001b[1;32m     70\u001b[0m \u001b[39melif\u001b[39;00m grid_param \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 71\u001b[0m     df_ref \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_ells_reference_dataframe(file_name, data_type)\n\u001b[1;32m     72\u001b[0m     df_ref\u001b[39m.\u001b[39mto_csv(save_ref_string)\n\u001b[1;32m     73\u001b[0m     df_ext \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_ells_dataframe(file_name, data_type)\n",
      "File \u001b[0;32m~/CosmoProjects/Looti_container/looti/looti/read_files.py:220\u001b[0m, in \u001b[0;36mFileReader.create_ells_reference_dataframe\u001b[0;34m(self, data_file_name, data_type)\u001b[0m\n\u001b[1;32m    217\u001b[0m dataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m    218\u001b[0m folder \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreference_folder\n\u001b[0;32m--> 220\u001b[0m observable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_files(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfolders_path, folder, data_file_name)\n\u001b[1;32m    221\u001b[0m ells_array \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_ells_array\n\u001b[1;32m    223\u001b[0m names \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mdata_type\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mredshift\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/CosmoProjects/Looti_container/looti/looti/read_files.py:310\u001b[0m, in \u001b[0;36mFileReader.read_files\u001b[0;34m(self, folders_path, folder_name, data_file_name)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[39mexcept\u001b[39;00m :\n\u001b[1;32m    308\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m observable  \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mloadtxt(folders_path \u001b[39m+\u001b[39;49m folder_name \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m data_file_name)\n\u001b[1;32m    312\u001b[0m \u001b[39mreturn\u001b[39;00m observable\n",
      "File \u001b[0;32m~/anaconda3/envs/looti/lib/python3.8/site-packages/numpy/lib/npyio.py:1356\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delimiter, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1354\u001b[0m     delimiter \u001b[39m=\u001b[39m delimiter\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1356\u001b[0m arr \u001b[39m=\u001b[39m _read(fname, dtype\u001b[39m=\u001b[39;49mdtype, comment\u001b[39m=\u001b[39;49mcomment, delimiter\u001b[39m=\u001b[39;49mdelimiter,\n\u001b[1;32m   1357\u001b[0m             converters\u001b[39m=\u001b[39;49mconverters, skiplines\u001b[39m=\u001b[39;49mskiprows, usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[1;32m   1358\u001b[0m             unpack\u001b[39m=\u001b[39;49munpack, ndmin\u001b[39m=\u001b[39;49mndmin, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1359\u001b[0m             max_rows\u001b[39m=\u001b[39;49mmax_rows, quote\u001b[39m=\u001b[39;49mquotechar)\n\u001b[1;32m   1361\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/anaconda3/envs/looti/lib/python3.8/site-packages/numpy/lib/npyio.py:975\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m    973\u001b[0m     fname \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(fname)\n\u001b[1;32m    974\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 975\u001b[0m     fh \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlib\u001b[39m.\u001b[39;49m_datasource\u001b[39m.\u001b[39;49mopen(fname, \u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mencoding)\n\u001b[1;32m    976\u001b[0m     \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         encoding \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fh, \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/looti/lib/python3.8/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[39m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[39mreturn\u001b[39;00m ds\u001b[39m.\u001b[39;49mopen(path, mode, encoding\u001b[39m=\u001b[39;49mencoding, newline\u001b[39m=\u001b[39;49mnewline)\n",
      "File \u001b[0;32m~/anaconda3/envs/looti/lib/python3.8/site-packages/numpy/lib/_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[39m=\u001b[39mmode,\n\u001b[1;32m    531\u001b[0m                               encoding\u001b[39m=\u001b[39mencoding, newline\u001b[39m=\u001b[39mnewline)\n\u001b[1;32m    532\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m not found.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: ../../raw_data/class_Asw0wa_DP_cmb_2K/0000/TE_cls.txt not found."
     ]
    }
   ],
   "source": [
    "Looti.create_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set all parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path and file name of the training data set (pandas dataframe)\n",
    "data_path = '../training_data/class_Asw0wa_DP_hypel_z0/'\n",
    "file_name = 'Plin'\n",
    "\n",
    "# type of observable to be emulated\n",
    "cosmo_quantity = 'Plin'\n",
    "\n",
    "# number of varying parameters in data set\n",
    "n_params = 7\n",
    "\n",
    "# set size of training and test data set\n",
    "n_train = 575\n",
    "n_test = 10\n",
    "\n",
    "# choose redshifts\n",
    "redshifts = [0]\n",
    "\n",
    "# choose if during training the logarithm of the grid and spectrum should be used\n",
    "features_to_Log = False\n",
    "observable_to_Log = False\n",
    "\n",
    "# choose number of PCA components\n",
    "ncomp = 20\n",
    "\n",
    "# option to have a seperate Gaussian process for each PCA component\n",
    "mult_gp = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LootiEmu_pk = cem.CosmoEmulator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the pandas data frame, perform seperation into training and test sets, and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LootiEmu_pk.read_data(cosmo_quantity=cosmo_quantity, \n",
    "                      data_path=data_path, \n",
    "                      file_name=file_name, \n",
    "                      n_params=n_params, \n",
    "                      n_train=n_train, \n",
    "                      n_test=n_test,\n",
    "                      redshifts=redshifts,\n",
    "                      features_to_Log=features_to_Log,\n",
    "                      observable_to_Log=observable_to_Log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LootiEmu_pk.create_emulator(cosmo_quantity=cosmo_quantity, n_params=n_params, mult_gp=mult_gp, ncomp=ncomp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the data and the trained emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emulation_data_pk = LootiEmu_pk.data[cosmo_quantity]\n",
    "intobj_pk = LootiEmu_pk.emu_objs[cosmo_quantity]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check convergence by evaluating the emulator on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters of training dataset\n",
    "xtrain = intobj_pk.trainspace_normed\n",
    "\n",
    "# target values of PCA components for the training dataset\n",
    "truth_normed_pcas_train = intobj_pk.representation\n",
    "\n",
    "if mult_gp == True:\n",
    "    # get predicted values of PCA components and uncertainty of the prediction from each GP\n",
    "    pred_temp = []\n",
    "    std_temp = []\n",
    "    for comp, gp in enumerate(intobj_pk.gp_dict.values()):\n",
    "        predictioncomp_train_temp, std_pca_train_temp = gp.predict(xtrain, return_std=True)\n",
    "        pred_temp.append(list(predictioncomp_train_temp))\n",
    "        std_temp.append(list(std_pca_train_temp))\n",
    "\n",
    "    # predicted values of PCA components for the training dataset\n",
    "    predictioncomp_train = np.array(pred_temp).T\n",
    "\n",
    "    # standard deviations of all predictions for the training dataset\n",
    "    std_pca_train = np.array(std_temp).T\n",
    "    \n",
    "else:\n",
    "    # get prediction of values for all PCA component from GP\n",
    "    predictioncomp_train, std_pca_train = intobj_pk.gp_regressor.predict(xtrain, return_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the residuals (target minus predicted values of PCA components) for a small subset of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at first 10 samples from training dataset\n",
    "n_plot_train = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_grid = np.linspace(1, n_plot_train, n_plot_train)\n",
    "fig, axs = plt.subplots(nrows=int(np.ceil(ncomp/2)), ncols=2)\n",
    "\n",
    "fig.suptitle('Residuals and Uncertainty of GP Predictions on Training Data Set')\n",
    "\n",
    "for comp in range(ncomp):\n",
    "    axs.ravel()[comp].errorbar(pca_grid, \n",
    "                 truth_normed_pcas_train[:n_plot_train][:,comp]-predictioncomp_train[:n_plot_train][:,comp], \n",
    "                 yerr=std_pca_train[:n_plot_train][:,comp], \n",
    "                 linestyle='', marker='.', color='cornflowerblue')\n",
    "    axs.ravel()[comp].hlines(0, 1, n_plot_train, color='firebrick', alpha=0.3)\n",
    "\n",
    "    axs.ravel()[comp].set_ylabel(\"Comp %i\" %(comp+1))\n",
    "    axs.ravel()[comp].set_xticks(list(range(1,n_plot_train+1)))\n",
    "    axs.ravel()[comp].set_xticklabels([])\n",
    "\n",
    "for i in range(2):\n",
    "    axs[-1, i].set_xlabel('Train data index')\n",
    "    axs[-1, i].set_xticks(list(range(1, n_plot_train+1)))\n",
    "    axs[-1, i].set_xticklabels(list(range(1, n_plot_train+1)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the emulator on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = (emulation_data_pk.test_samples - intobj_pk.trainspace_mean) / intobj_pk.trainspace_std\n",
    "\n",
    "if mult_gp == True:\n",
    "    pred_temp = []\n",
    "    std_temp = []\n",
    "    for comp, gp in enumerate(intobj_pk.gp_dict.values()):\n",
    "        predictioncomp_test_temp, std_pca_test_temp = gp.predict(xtest, return_std=True)\n",
    "        pred_temp.append(list(predictioncomp_test_temp))\n",
    "        std_temp.append(list(std_pca_test_temp))\n",
    "        \n",
    "    predictioncomp_test = np.array(pred_temp).T\n",
    "    std_pca_test = np.array(std_temp).T\n",
    "    \n",
    "else:\n",
    "    predictioncomp_test, std_pca_test = intobj_pk.gp_regressor.predict(xtest, return_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA on the test data to get target values for all PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparam = emulation_data_pk.num_parameters + int(emulation_data_pk.multiple_z)\n",
    "if emulation_data_pk.multiple_z:\n",
    "    params = ['z']\n",
    "else:\n",
    "    params = []\n",
    "params += list(emulation_data_pk.paramnames_dict.values())\n",
    "\n",
    "truth_normed_pcas_list = []\n",
    "for ii in range(emulation_data_pk.test_samples.shape[0]):\n",
    "    indexvalues = emulation_data_pk.test_samples[ii]\n",
    "    if emulation_data_pk.multiple_z:\n",
    "        index_list = emulation_data_pk.data_type, indexvalues[0], params[1], indexvalues[1], params[2], indexvalues[2], params[3], indexvalues[3], params[4], indexvalues[4], params[5], indexvalues[5]\n",
    "    else:\n",
    "        index_list = emulation_data_pk.data_type, 0.0, params[0], indexvalues[0], params[1], indexvalues[1], params[2], indexvalues[2], params[3], indexvalues[3], params[4], indexvalues[4], params[5], indexvalues[5]\n",
    "\n",
    "    truth_spectrum_test = emulation_data_pk.df_ext.loc[index_list].values.flatten()\n",
    "    ref_spectrum = emulation_data_pk.df_ref.loc[emulation_data_pk.data_type, 0.0].values.flatten()\n",
    "\n",
    "    truth_spectrum_normed_test = ((truth_spectrum_test/ref_spectrum) - emulation_data_pk.binwise_mean) / emulation_data_pk.binwise_std\n",
    "    truth_pca_test_raw = intobj_pk.pca.transform([truth_spectrum_normed_test]).flatten()\n",
    "    truth_pca_test = (truth_pca_test_raw - intobj_pk.matPCA_mean) / intobj_pk.matPCA_std\n",
    "    truth_normed_pcas_list.append(truth_pca_test)\n",
    "\n",
    "truth_normed_pcas = np.array(truth_normed_pcas_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the residuals (target minus predicted values of PCA components) for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = len(emulation_data_pk.test_samples)\n",
    "pca_grid = np.linspace(1, n_test, n_test)\n",
    "fig, axs = plt.subplots(nrows=int(np.ceil(ncomp/2)), ncols=2)\n",
    "\n",
    "fig.suptitle('Residuals and Uncertainty of GP Predictions on Test Data Set')\n",
    "\n",
    "for comp in range(ncomp):\n",
    "    axs.ravel()[comp].errorbar(pca_grid, \n",
    "                 truth_normed_pcas[:,comp]-predictioncomp_test[:,comp], \n",
    "                 yerr=std_pca_test[:,comp], \n",
    "                 linestyle='', marker='.', color='cornflowerblue')\n",
    "    axs.ravel()[comp].hlines(0, 1, n_test, color='firebrick', alpha=0.3)\n",
    "\n",
    "    axs.ravel()[comp].set_ylabel(\"Comp %i\" %(comp+1))\n",
    "    axs.ravel()[comp].set_xticks(list(range(1,n_test+1)))\n",
    "    axs.ravel()[comp].set_xticklabels([])\n",
    "\n",
    "for i in range(2):\n",
    "    axs[-1, i].set_xlabel('Test data index')\n",
    "    axs[-1, i].set_xticks(list(range(1, n_test+1)))\n",
    "    axs[-1, i].set_xticklabels(list(range(1, n_test+1)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the predicted vs. true spectra, and the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LootiEmu_pk.get_params(cosmo_quantity=cosmo_quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data_pk.df_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.cm.coolwarm(np.linspace(0, 1, len(emulation_data_pk.test_samples)))\n",
    "fig, ax =plt.subplots(3, figsize=(7, 6))\n",
    "fig.set_tight_layout(tight=True)\n",
    "\n",
    "# get a list of the varying parameters\n",
    "params_varying = list(LootiEmu_pk.get_params(cosmo_quantity=cosmo_quantity).keys())\n",
    "\n",
    "# get true target spectra of the test dataset\n",
    "test_indices = emulation_data_pk.test_splitdict[0]\n",
    "truth_spectrum = emulation_data_pk.df_ext.loc[cosmo_quantity].values[test_indices]\n",
    "\n",
    "for plot_index, color in enumerate(colors):\n",
    "    # create input dictionary with values of test sample for each parameter\n",
    "    input_values = emulation_data_pk.test_samples[plot_index]\n",
    "    input_dict_pk = dict()\n",
    "    for param, value in zip(params_varying, input_values):\n",
    "        input_dict_pk[param] = value\n",
    "\n",
    "    # get the grid and the predicted spectrum for the given input\n",
    "    grid_temp, pk_test = LootiEmu_pk.get_prediction(cosmo_quantity=cosmo_quantity, input_dict=input_dict_pk)\n",
    "\n",
    "    # transform grid in case it is given logarithmically\n",
    "    if features_to_Log==True:\n",
    "        grid = np.power(10, grid_temp)\n",
    "    else:\n",
    "        grid = grid_temp\n",
    "\n",
    "    # get the target spectra for current index in test dataset\n",
    "    pk_truth = truth_spectrum[plot_index]\n",
    "\n",
    "    # upper plot: target and predicted spectrum \n",
    "    ax[0].loglog(grid, pk_truth, c='cornflowerblue', label='truth')\n",
    "    ax[0].loglog(grid, pk_test, c='firebrick', linestyle='--', label='prediction')\n",
    "\n",
    "    # middle plot: relative residuals\n",
    "    residuals = 1 - pk_test / truth_spectrum[plot_index]\n",
    "    ax[1].semilogx(grid, residuals, color=color)\n",
    "\n",
    "    # lower plot: absolute residuals\n",
    "    residuals = pk_test - truth_spectrum[plot_index]\n",
    "    ax[2].semilogx(grid, residuals, color=color)\n",
    "\n",
    "# set lables and title\n",
    "ax[0].set_title('Prediction and Residuals for %i test samples' %(len(emulation_data_pk.test_samples)))\n",
    "ax[0].set_ylabel('Spectra')\n",
    "ax[0].set_xticklabels([])\n",
    "ax[1].set_ylabel('Relative Residuals')\n",
    "ax[1].set_xticklabels([])\n",
    "ax[2].set_xlabel(r'$k$')\n",
    "ax[2].set_ylabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose path and file name to save trained emulator and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../emulators/'\n",
    "save_name = cosmo_quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save emulator and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(emulation_data_pk, open(save_path+save_name+'test_data.sav', 'wb'))\n",
    "pickle.dump(intobj_pk, open(save_path+save_name+'test.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lootiemu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
