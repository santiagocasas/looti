{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create looti emulators for observables dependent on z & k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: linear power spectrum $P_{lin}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Create a pandas dataframe from data files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load looti module read_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from looti import read_files as rf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path to the data files and other specifications are passed to looti via a yaml file.\n",
    "The yaml file should contain the following information:\n",
    "- main_dir: the directory in which all relevant folders and files are stored\n",
    "- config_file: this file should include a section called where the varying parameters are specified\n",
    "\n",
    "- folders_path: path to the directory containing all the data folders, one for each class/camb run\n",
    "- params_file: each data folder should contain a file specifying the values of each parameter for this run\n",
    "- reference folder: name of the folder containing a run with fiducial values used as reference\n",
    "\n",
    "- z_file_name: file containing the redshift grid\n",
    "- k_file_name: file containing the k grid\n",
    "- data_file_name: file containing the data to be emulated\n",
    "- data_type: name of observable to be emulated"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of \"FrameConstructor\" - the looti class used for data management.\n",
    "FrameConstructor takes the path to this yamle file as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameConstructor = rf.FrameConstructor(path_config_file='../readfile_configs/input4cast_lhs_Plin.yaml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe containing all training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_ext = FrameConstructor.create_k_dataframe()\n",
    "dataframe_ext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe_ext.to_csv(\"../data/rwth_output/mg_camb_lhs_log10fR0/Plin.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe containing reference at fiducial values for the varying parameters at each redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_ref = FrameConstructor.create_k_reference_dataframe()\n",
    "dataframe_ref"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the reference dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe_ref.to_csv(\"../data/rwth_output/mg_camb_lhs_log10fR0/Plin_ref.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_all = pd.read_csv('../data/rwth_output/mg_camb_lhs_log10fR0/Plin.csv', index_col=list(range(14)))\n",
    "df_z0 = df_all[df_all.index.get_level_values('redshift')==0]\n",
    "df_k = df_all[df_all.index.get_level_values('data_type')=='k_grid']\n",
    "df_fin = pd.concat([df_z0, df_k])\n",
    "df_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fin.to_csv('../data/rwth_output/mg_camb_lhs_log10fR0/Plin_z0_ref.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Normalize the data and divide it into training, validation and test sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load looti module datahandle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from looti import datahandle as dhl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify path and names of the pandas dataframes we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../data/rwth_output/mg_camb_lhs_log10fR0/' \n",
    "datafile_ext = 'Plin'\n",
    "datafile_ref = 'Plin_ref'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataHandle object and read the csv files containing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data = dhl.DataHandle(datafile_ext,                   # file name of csv file containing input data\n",
    "                                data_folder,                    # path to folder containing both external and reference dataframes\n",
    "                                datafile_ref,                   # file name of csv file containing reference data\n",
    "                                num_parameters=6,               # number of parameters to be interpolated\n",
    "                                data_type='Plin',               # type of observable to be emulated\n",
    "                                features_name='k_grid',         # name of the grid in the data frames\n",
    "                                features_to_Log=True,           # \n",
    "                                normalize_by_reference=True,\n",
    "                                normalize_by_mean_std=True) \n",
    "emulation_data.read_csv_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data (by dividing through the reference and then normalizing by mean and standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data.calculate_ratio_by_redshifts(emulation_data.z_vals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the desired number of training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np \n",
    "\n",
    "n_train = 310                                               # Number of training vectors without taking acount the extrema \n",
    "n_test = 10                                                 # Number of test vectors without taking acount the extrema\n",
    "test_indices=[random.sample(range(1, 1000), n_test)]        # List of list -of test indices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training, validation and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data.calculate_data_split(n_train=n_train,                            # Number of training vectors per redshift\n",
    "                                    n_test=n_test,                              # Number of test vectors per redsift\n",
    "                                    verbosity=3,\n",
    "                                    manual_split=True,\n",
    "                                    test_indices=None,\n",
    "                                    train_redshift_indices=list(range(5)),      # Indices of the redshifts used for the train vect.\n",
    "                                    test_redshift_indices=list(range(5)))       # Indices of the redshifts used for the test vect."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) PCA and GP interpolation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the looti module dictlearn which is used for PCA transformation and the training of intepolators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from looti import dictlearn as dcl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the number of PCA components and specify the number of varying parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npca = 9\n",
    "nparam = 7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is transformed into PCA space and a Gaussian Process (GP) is trained on the PCA components. \n",
    "<br>\n",
    "<br>\n",
    "Required input:\n",
    "- emulation_data\n",
    "\n",
    "\n",
    "Optional input:\n",
    "- Operator: type of interpolation (default = 'PCA')\n",
    "    - LIN: interpolation according to a simple spline\n",
    "    - PCA: interpolation over PCA components\n",
    "    - DL: interpolation over dictionary components of sparse DL representation\n",
    "    - GP: directly train a Gaussian Process on the data without further pre-processing\n",
    "- interp_type: type of interpolator\n",
    "    - GP: Gaussian Process\n",
    "    - int1d:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_predicted, emulation_data, intobj = dcl.Predict_ratio(emulation_data,Operator=\"PCA\",\n",
    "                                                             train_noise=1e-10,                     # Noise for the GP's kernel\n",
    "                                                             gp_n_rsts=200,                          # max times to restart the optimiser\n",
    "                                                             ncomp=npca,                            # Number of components\n",
    "                                                             gp_const=1,                            # Constant for the RBF kernel\n",
    "                                                             gp_length=np.ones(nparam),            # Length for GP \n",
    "                                                             interp_type='GP',                      # Kind of interpolator\n",
    "                                                             test_indices=test_indices,             # Indices of test vectors\n",
    "                                                             interp_dim=1,\n",
    "                                                             return_interpolator=True,\n",
    "                                                             pca_norm=True,\n",
    "                                                             train_redshift_indices=list(range(5)),\n",
    "                                                             test_redshift_indices=list(range(5))\n",
    "                                                             )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Save the trained interpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../interpolators/redshift_0/'\n",
    "intobj_name = 'pca9_nrsts200_aniso.sav'\n",
    "data_name = 'pca9_nrsts200_aniso_data.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(intobj, open(save_path+intobj_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(emulation_data, open(save_path+data_name, 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now repeat the same procedure for the other observables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Non-linear power spectrum $P_{nonlin}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameConstructor = rf.FrameConstructor(path_config_file='../readfile_configs/input4cast_lhs_Pnonlin.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_Pnonlin_ext = FrameConstructor.create_k_dataframe()\n",
    "dataframe_Pnonlin_ext.to_csv(\"../data/rwth_output/class_Asw0wa_DP/Pnonlin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_Pnonlin_ref = FrameConstructor.create_k_reference_dataframe()\n",
    "dataframe_Pnonlin_ref.to_csv(\"../data/rwth_output/class_Asw0wa_DP/Pnonlin_ref.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../data/rwth_output/class_Asw0wa_DP/' \n",
    "datafile_ext = 'Pnonlin'\n",
    "datafile_ref = 'Pnonlin_ref'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data = dhl.DataHandle(datafile_ext,                   # file name of csv file containing input data\n",
    "                                data_folder,                    # path to folder containing both external and reference dataframes\n",
    "                                datafile_ref,                   # file name of csv file containing reference data\n",
    "                                num_parameters=7,               # number of parameters to be interpolated\n",
    "                                data_type='Pnonlin',            # type of observable to be emulated\n",
    "                                features_name='k_grid',         # name of the grid in the data frames\n",
    "                                features_to_Log=True,           # \n",
    "                                normalize_by_reference=True,\n",
    "                                normalize_by_mean_std=True) \n",
    "\n",
    "emulation_data.read_csv_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data.calculate_ratio_by_redshifts(emulation_data.z_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 100                                                  # Number of training vectors without taking acount the extrema \n",
    "n_test = 2                                                     # Number of test vectors without taking acount the extrema\n",
    "test_indices=[random.sample(range(1, 1000), n_test)]           # List of list -of test indices, one list per split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data.calculate_data_split(n_train=n_train,                            # Number of training vectors per redshift\n",
    "                                    n_test=n_test,                              # Number of test vectors per redsift\n",
    "                                    verbosity=3,\n",
    "                                    manual_split=True,\n",
    "                                    test_indices=None,\n",
    "                                    train_redshift_indices=list(range(5)),      # Indices of the redshifts used for the train vect.\n",
    "                                    test_redshift_indices=list(range(5)))       # Indices of the redshifts used for the test vect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npca = 7\n",
    "nparam = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_predicted, emulation_data, intobj = dcl.Predict_ratio(emulation_data,Operator=\"PCA\",\n",
    "                                                             train_noise=1e-10,                     # Noise for the GP's kernel\n",
    "                                                             gp_n_rsts=100,                          # max times to restart the optimiser\n",
    "                                                             ncomp=npca,                            # Number of components\n",
    "                                                             gp_const=1,                            # Constant for the RBF kernel\n",
    "                                                             gp_length=1,            # Length for GP \n",
    "                                                             interp_type='GP',                      # Kind of interpolator\n",
    "                                                             test_indices=test_indices,             # Indices of test vectors\n",
    "                                                             interp_dim=1,\n",
    "                                                             return_interpolator=True,\n",
    "                                                             pca_norm=True,\n",
    "                                                             train_redshift_indices=list(range(5)),\n",
    "                                                             test_redshift_indices=list(range(5))\n",
    "                                                             # min_k =1e-2,ma_k=10e1\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_path = '../interpolators/class_Asw0wa_DP/'\n",
    "save_name = 'Pnonlin.sav'\n",
    "data_name = 'Pnonlin_data.sav'\n",
    "pickle.dump(intobj, open(save_path+save_name, 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Growth factor $D$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from looti import datahandle as dhl\n",
    "from looti import dictlearn as dcl\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameConstructor = rf.FrameConstructor(path_config_file='../readfile_configs/input4cast_lhs_D_Growth.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_D_Growth_ext = FrameConstructor.create_k_dataframe()\n",
    "dataframe_D_Growth_ext.to_csv(\"../data/rwth_output/class_Asw0wa_DP/D_Growth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_D_Growth_ref = FrameConstructor.create_k_reference_dataframe()\n",
    "dataframe_D_Growth_ref.to_csv(\"../data/rwth_output/class_Asw0wa_DP/D_Growth_ref.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../data/rwth_output/class_Asw0wa_DP/'\n",
    "datafile_ext = 'D_Growth'\n",
    "datafile_ref = 'D_Growth_ref'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data = dhl.DataHandle(datafile_ext,                   # file name of csv file containing input data\n",
    "                                data_folder,                    # path to folder containing both external and reference dataframes\n",
    "                                datafile_ref,                   # file name of csv file containing reference data\n",
    "                                num_parameters=7,               # number of parameters to be interpolated\n",
    "                                data_type='D_Growth',           # type of observable to be emulated\n",
    "                                features_name='k_grid',         # name of the grid in the data frames\n",
    "                                features_to_Log=True,           # \n",
    "                                normalize_by_reference=True,\n",
    "                                normalize_by_mean_std=True) \n",
    "emulation_data.read_csv_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data.calculate_ratio_by_redshifts(emulation_data.z_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 100                                                  # Number of training vectors without taking acount the extrema \n",
    "n_test = 2                                                     # Number of test vectors without taking acount the extrema\n",
    "test_indices=[random.sample(range(1, 1000), n_test)]           # List of list -of test indices, one list per split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data.calculate_data_split(n_train=n_train,                            # Number of training vectors per redshift\n",
    "                                    n_test=n_test,                              # Number of test vectors per redsift\n",
    "                                    verbosity=3,\n",
    "                                    manual_split=True,\n",
    "                                    test_indices=None,\n",
    "                                    train_redshift_indices=list(range(5)),      # Indices of the redshifts used for the train vect.\n",
    "                                    test_redshift_indices=list(range(5)))       # Indices of the redshifts used for the test vect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npca = 7\n",
    "nparam = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_predicted, emulation_data, intobj = dcl.Predict_ratio(emulation_data,Operator=\"PCA\",\n",
    "                                                             train_noise=1e-10,                     # Noise for the GP's kernel\n",
    "                                                             gp_n_rsts=40,                          # max times to restart the optimiser\n",
    "                                                             ncomp=npca,                            # Number of components\n",
    "                                                             gp_const=1,                            # Constant for the RBF kernel\n",
    "                                                             gp_length=np.ones(nparam) ,            # Length for GP \n",
    "                                                             interp_type='GP',                      # Kind of interpolator\n",
    "                                                             test_indices=test_indices,             # Indices of test vectors\n",
    "                                                             interp_dim=1,\n",
    "                                                             return_interpolator=True,\n",
    "                                                             pca_norm=True,\n",
    "                                                             train_redshift_indices=list(range(5)),\n",
    "                                                             test_redshift_indices=list(range(5))\n",
    "                                                             # min_k =1e-2,ma_k=10e1\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_path = '../interpolators/class_Asw0wa_DP/'\n",
    "save_name = 'D_Growth.sav'\n",
    "data_name = 'D_Growth_data.sav'\n",
    "pickle.dump(intobj, open(save_path+save_name, 'wb'))\n",
    "pickle.dump(emulation_data, open(save_path+data_name, 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Growth rate $f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from looti import datahandle as dhl\n",
    "from looti import dictlearn as dcl\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameConstructor = rf.FrameConstructor(path_config_file='../readfile_configs/input4cast_lhs_f_GrowthRate.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_f_GrowthRate_ext = FrameConstructor.create_k_dataframe()\n",
    "dataframe_f_GrowthRate_ext.to_csv(\"../data/rwth_output/class_Asw0wa_DP/f_GrowthRate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_f_GrowthRate_ref = FrameConstructor.create_k_reference_dataframe()\n",
    "dataframe_f_GrowthRate_ref.to_csv(\"../data/rwth_output/class_Asw0wa_DP/f_GrowthRate_ref.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../data/rwth_output/class_Asw0wa_DP/'\n",
    "datafile_ext = 'f_GrowthRate'\n",
    "datafile_ref = 'f_GrowthRate_ref'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data = dhl.DataHandle(datafile_ext,                   # file name of csv file containing input data\n",
    "                                data_folder,                    # path to folder containing both external and reference dataframes\n",
    "                                datafile_ref,                   # file name of csv file containing reference data\n",
    "                                num_parameters=7,               # number of parameters to be interpolated\n",
    "                                data_type='f_GrowthRate',       # type of observable to be emulated\n",
    "                                features_name='k_grid',         # name of the grid in the data frames\n",
    "                                features_to_Log=True,           # \n",
    "                                normalize_by_reference=True,\n",
    "                                normalize_by_mean_std=True) \n",
    "emulation_data.read_csv_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data.calculate_ratio_by_redshifts(emulation_data.z_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 100                                                  # Number of training vectors without taking acount the extrema \n",
    "n_test = 2                                                     # Number of test vectors without taking acount the extrema\n",
    "test_indices=[random.sample(range(1, 1000), n_test)]           # List of list -of test indices, one list per split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data.calculate_data_split(n_train=n_train,                            # Number of training vectors per redshift\n",
    "                                    n_test=n_test,                              # Number of test vectors per redsift\n",
    "                                    verbosity=3,\n",
    "                                    manual_split=True,\n",
    "                                    test_indices=None,\n",
    "                                    train_redshift_indices=list(range(5)),      # Indices of the redshifts used for the train vect.\n",
    "                                    test_redshift_indices=list(range(5)))       # Indices of the redshifts used for the test vect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npca = 7\n",
    "nparam = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_predicted, emulation_data, intobj = dcl.Predict_ratio(emulation_data,Operator=\"PCA\",\n",
    "                                                             train_noise=1e-10,                     # Noise for the GP's kernel\n",
    "                                                             gp_n_rsts=40,                          # max times to restart the optimiser\n",
    "                                                             ncomp=npca,                            # Number of components\n",
    "                                                             gp_const=1,                            # Constant for the RBF kernel\n",
    "                                                             gp_length=np.ones(nparam) ,            # Length for GP \n",
    "                                                             interp_type='GP',                      # Kind of interpolator\n",
    "                                                             test_indices=test_indices,             # Indices of test vectors\n",
    "                                                             interp_dim=1,\n",
    "                                                             return_interpolator=True,\n",
    "                                                             pca_norm=True,\n",
    "                                                             train_redshift_indices=list(range(5)),\n",
    "                                                             test_redshift_indices=list(range(5))\n",
    "                                                             # min_k =1e-2,ma_k=10e1\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_path = '../interpolators/class_Asw0wa_DP/'\n",
    "save_name = 'f_GrowthRate.sav'\n",
    "data_name = 'f_GrowthRate_data.sav'\n",
    "pickle.dump(intobj, open(save_path+save_name, 'wb'))\n",
    "pickle.dump(emulation_data, open(save_path+data_name, 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: $\\Sigma_{WL}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from looti import datahandle as dhl\n",
    "from looti import dictlearn as dcl\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameConstructor = rf.FrameConstructor(path_config_file='../readfile_configs/input4cast_lhs_sigmaWL.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_sigmaWL_ext = FrameConstructor.create_k_dataframe()\n",
    "dataframe_sigmaWL_ext.to_csv(\"../data/rwth_output/class_Asw0wa_DP/sigmaWL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_sigmaWL_ref = FrameConstructor.create_k_reference_dataframe()\n",
    "dataframe_sigmaWL_ref.to_csv(\"../data/rwth_output/class_Asw0wa_DP/sigmaWL_ref.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../data/rwth_output/class_Asw0wa_DP/'\n",
    "datafile_ext = 'sigmaWL'\n",
    "datafile_ref = 'sigmaWL_ref'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data = dhl.DataHandle(datafile_ext,                   # file name of csv file containing input data\n",
    "                                data_folder,                    # path to folder containing both external and reference dataframes\n",
    "                                datafile_ref,                   # file name of csv file containing reference data\n",
    "                                num_parameters=7,               # number of parameters to be interpolated\n",
    "                                data_type='sigmaWL',           # type of observable to be emulated\n",
    "                                features_name='k_grid',         # name of the grid in the data frames\n",
    "                                features_to_Log=True,           # \n",
    "                                normalize_by_reference=True,\n",
    "                                normalize_by_mean_std=True) \n",
    "emulation_data.read_csv_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data.calculate_ratio_by_redshifts(emulation_data.z_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 100                                                  # Number of training vectors without taking acount the extrema \n",
    "n_test = 2                                                     # Number of test vectors without taking acount the extrema\n",
    "test_indices=[random.sample(range(1, 1000), n_test)]           # List of list -of test indices, one list per split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data.calculate_data_split(n_train=n_train,                            # Number of training vectors per redshift\n",
    "                                    n_test=n_test,                              # Number of test vectors per redsift\n",
    "                                    verbosity=3,\n",
    "                                    manual_split=True,\n",
    "                                    test_indices=None,\n",
    "                                    train_redshift_indices=list(range(5)),      # Indices of the redshifts used for the train vect.\n",
    "                                    test_redshift_indices=list(range(5)))       # Indices of the redshifts used for the test vect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npca = 7\n",
    "nparam = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulation_data.matrix_ratios_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_predicted, emulation_data, intobj = dcl.Predict_ratio(emulation_data,Operator=\"PCA\",\n",
    "                                                             train_noise=1e-10,                     # Noise for the GP's kernel\n",
    "                                                             gp_n_rsts=40,                          # max times to restart the optimiser\n",
    "                                                             ncomp=npca,                            # Number of components\n",
    "                                                             gp_const=1,                            # Constant for the RBF kernel\n",
    "                                                             gp_length=np.ones(nparam) ,            # Length for GP \n",
    "                                                             interp_type='GP',                      # Kind of interpolator\n",
    "                                                             test_indices=test_indices,             # Indices of test vectors\n",
    "                                                             interp_dim=1,\n",
    "                                                             return_interpolator=True,\n",
    "                                                             pca_norm=True,\n",
    "                                                             train_redshift_indices=list(range(5)),\n",
    "                                                             test_redshift_indices=list(range(5))\n",
    "                                                             # min_k =1e-2,ma_k=10e1\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_path = '../interpolators/class_Asw0wa_DP/'\n",
    "save_name = 'sigmaWL.sav'\n",
    "data_name = 'sigmaWL_data.sav'\n",
    "pickle.dump(intobj, open(save_path+save_name, 'wb'))\n",
    "pickle.dump(emulation_data, open(save_path+data_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lootiemu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
